{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import pytesseract\n",
    "import sys\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Program digits detection using openCV contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_bounds(s, target):\n",
    "    return target == 0 or (s/target >= 0.7 and s/target <= 1.3)\n",
    "\n",
    "def digitGenerator(thresh, height_of_digit, width_of_digit, x_pos = 0, y_pos = 0):\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(cnt)\n",
    "        if (in_bounds(w, width_of_digit) and in_bounds(h, height_of_digit)):\n",
    "            #print(\"Accept:\", x, y, w, h)\n",
    "            if (x_pos != 0 and x >= x_pos - 25 == False) or (y_pos != 0 and in_bounds(y, y_pos) == False):\n",
    "                continue\n",
    "            cv2.rectangle(thresh, (x - 1, y - 1), (x + 1 + w, y + 1 + h), (0, 0, 255), 1)\n",
    "            roi = thresh[y:y + h, x:x + w]\n",
    "            roi = cv2.adaptiveThreshold(roi,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,21,11)\n",
    "            yield roi\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"Out of bound:\", x, y, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Manually configure convolution digit detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(name, img):\n",
    "    plt.imshow(img)\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"./courrier-font.png\")\n",
    "imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 150, 255, 0)\n",
    "plot_img('thresh', thresh)\n",
    "width_of_digit = 58\n",
    "height_of_digit = 84\n",
    "            \n",
    "digitsModels = [[None]] * 11\n",
    "for roi in digitGenerator(thresh, height_of_digit, width_of_digit):\n",
    "    cv2.imshow('Training: Enter digits displayed in the red rectangle!', roi)\n",
    "    key = cv2.waitKey(0)\n",
    "    keys = [i for i in range(48, 58)]\n",
    "    keys.append(121)\n",
    "    if key in keys:\n",
    "        if key != 121: \n",
    "            digitsModels[key - 48] = roi\n",
    "        else:\n",
    "            digitsModels[10] = roi\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def detect_number(digit, candidate):\n",
    "    dgt = digit\n",
    "    if (candidate.shape != dgt.shape):\n",
    "        dgt = cv2.resize(dgt, np.transpose(candidate).shape)\n",
    "    dgt[np.where(dgt > 80)] = 255\n",
    "    dgt[np.where(dgt <= 80)] = 0\n",
    "    conv = np.multiply(dgt, candidate)\n",
    "    return np.sum(np.sum(conv))\n",
    "\n",
    "def recognize_digit(candidate):\n",
    "    convs = [detect_number(digit, candidate) for digit in digitsModels]\n",
    "    print(candidate.shape, convs)\n",
    "    return convs.index(max(convs))\n",
    "\n",
    "recognize_digit(digitsModels[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Program text detection using openCV EAST trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(scores, geometry, scoreThresh):\n",
    "    detections = []\n",
    "    confidences = []\n",
    "\n",
    "    ############ CHECK DIMENSIONS AND SHAPES OF geometry AND scores ############\n",
    "    assert len(scores.shape) == 4, \"Incorrect dimensions of scores\"\n",
    "    assert len(geometry.shape) == 4, \"Incorrect dimensions of geometry\"\n",
    "    assert scores.shape[0] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[0] == 1, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[1] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[1] == 5, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[2] == geometry.shape[2], \"Invalid dimensions of scores and geometry\"\n",
    "    assert scores.shape[3] == geometry.shape[3], \"Invalid dimensions of scores and geometry\"\n",
    "    height = scores.shape[2]\n",
    "    width = scores.shape[3]\n",
    "    for y in range(0, height):\n",
    "\n",
    "        # Extract data from scores\n",
    "        scoresData = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        anglesData = geometry[0][4][y]\n",
    "        for x in range(0, width):\n",
    "            score = scoresData[x]\n",
    "\n",
    "            # If score is lower than threshold score, move to next x\n",
    "            if(score < scoreThresh):\n",
    "                continue\n",
    "\n",
    "            # Calculate offset\n",
    "            offsetX = x * 4.0\n",
    "            offsetY = y * 4.0\n",
    "            angle = anglesData[x]\n",
    "\n",
    "            # Calculate cos and sin of angle\n",
    "            cosA = math.cos(angle)\n",
    "            sinA = math.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "\n",
    "            # Calculate offset\n",
    "            offset = ([offsetX + cosA * x1_data[x] + sinA * x2_data[x], offsetY - sinA * x1_data[x] + cosA * x2_data[x]])\n",
    "\n",
    "            # Find points for rectangle\n",
    "            p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "            p3 = (-cosA * w + offset[0],  sinA * w + offset[1])\n",
    "            center = (0.5*(p1[0]+p3[0]), 0.5*(p1[1]+p3[1]))\n",
    "            detections.append((center, (w,h), -1*angle * 180.0 / math.pi))\n",
    "            confidences.append(float(score))\n",
    "\n",
    "    # Return detections and confidences\n",
    "    return [detections, confidences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./frozen_east_text_detection.pb\"\n",
    "\n",
    "def detect_text(frame, model):\n",
    "    inpWidth = 320\n",
    "    inpHeight = 320\n",
    "    confThreshold = 0.5\n",
    "    nmsThreshold = 0.4\n",
    "    try: \n",
    "        # Load network\n",
    "        net = cv2.dnn.readNet(model)\n",
    "        outNames = []\n",
    "        outNames.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "        outNames.append(\"feature_fusion/concat_3\")\n",
    "\n",
    "        # Get frame height and width\n",
    "        height_ = frame.shape[0]\n",
    "        width_ = frame.shape[1]\n",
    "        rW = width_ / float(inpWidth)\n",
    "        rH = height_ / float(inpHeight)\n",
    "\n",
    "        # Create a 4D blob from frame.\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (inpWidth, inpHeight), (123.68, 116.78, 103.94), True, False)\n",
    "        imgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #imgray = cv2.adaptiveThreshold(imgray, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,21,5)\n",
    "\n",
    "        # Run the model\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(outNames)\n",
    "        t, _ = net.getPerfProfile()\n",
    "\n",
    "        # Get scores and geometry\n",
    "        scores = outs[0]\n",
    "        geometry = outs[1]\n",
    "        [boxes, confidences] = decode(scores, geometry, confThreshold)\n",
    "\n",
    "        # Apply NMS\n",
    "        indices = cv2.dnn.NMSBoxesRotated(boxes, confidences, confThreshold,nmsThreshold)\n",
    "        for i in indices:\n",
    "            # get 4 corners of the rotated rect\n",
    "            vertices = cv2.boxPoints(boxes[i[0]])\n",
    "\n",
    "            # scale the bounding box coordinates based on the respective ratios\n",
    "            for j in range(4):\n",
    "                vertices[j][0] *= rW\n",
    "                vertices[j][1] *= rH\n",
    "\n",
    "            # Display square\n",
    "            x,y,w,h = cv2.boundingRect(vertices)\n",
    "            #rect = cv2.rectangle(imgray,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            roi = imgray[y:y + h, x:x + w]\n",
    "            roi = cv2.adaptiveThreshold(roi,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,21,5)\n",
    "            yield (roi, x, y, w, h)\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detected_text(img, config = (\"\")):\n",
    "    img_height, img_width, _ = img.shape\n",
    "    for (roi, x, y, w, h) in detect_text(img, model):\n",
    "        if roi is None:\n",
    "            continue\n",
    "        plot_img('Detected text!', roi)\n",
    "        print(\"Detected at (x,y,w,h) = \", x, y, w, h)\n",
    "        print(\"Relative at (x,y,w,h) = \", x/img_width, y/img_height, w/img_width, h/img_height)\n",
    "        text = pytesseract.image_to_string(roi, config=config)\n",
    "        if text:\n",
    "            print(text)\n",
    "        else:\n",
    "            print(\"Cannot read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img_price(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    shape = img.shape # shape = height * width * color\n",
    "    crop_img = img[int(shape[0]/2):,int(shape[1]/2):]\n",
    "    return crop_img\n",
    "\n",
    "def crop_img_id(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    shape = img.shape # shape = height * width * color\n",
    "    crop_img = img[:int(shape[0]/2),int(shape[1]/2):]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits_convolution(im):\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(imgray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,21,5)\n",
    "    plot_img('thresh', thresh)\n",
    "\n",
    "    # price\n",
    "    width_of_digit = 10\n",
    "    height_of_digit = 20\n",
    "\n",
    "    # fapiao id\n",
    "    width_of_digit = 15\n",
    "    height_of_digit = 40\n",
    "\n",
    "    pos_x = 120\n",
    "    pos_y = 515\n",
    "\n",
    "    pos_x = 20\n",
    "    pos_y = 11\n",
    "\n",
    "    for roi in digitGenerator(thresh, height_of_digit, width_of_digit, pos_x, pos_y):          \n",
    "        cv2.imshow('Training: Enter digits displayed in the red rectangle!', roi)\n",
    "        config = (\"\")\n",
    "        print(pytesseract.image_to_string(roi, config=config))\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"./fapiao/electronic/031001800211-46.62.png\")\n",
    "detect_digits_convolution(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./fapiao/electronic/031001800211-46.62.png\")\n",
    "config = (\"--tessdata-dir ./tesseract/ --l chi_sim --psm 3\")\n",
    "display_detected_text(img, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./fapiao/IMG_20190312_102624.jpg\")\n",
    "crop_img = crop_img_price(img)\n",
    "plot_img(\"cropped\", crop_img)\n",
    "display_detected_text(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./fapiao/IMG_20190312_102653.jpg\")\n",
    "crop_img = crop_img_id(img)\n",
    "plot_img(\"cropped\", crop_img)\n",
    "display_detected_text(crop_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_detect(img,ele_size=(8,2)): #\n",
    "    if len(img.shape)==3:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_sobel = cv2.Sobel(img,cv2.CV_8U,1,0)#same as default,None,3,1,0,cv2.BORDER_DEFAULT)\n",
    "    img_threshold = cv2.threshold(img_sobel,0,255,cv2.THRESH_OTSU+cv2.THRESH_BINARY)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT,ele_size)\n",
    "    img_threshold = cv2.morphologyEx(img_threshold[1],cv2.MORPH_CLOSE,element)\n",
    "    contours, _ = cv2.findContours(img_threshold,0,1)\n",
    "    Rect = [cv2.boundingRect(i) for i in contours if i.shape[0]>100]\n",
    "    RectP = [(int(i[0]-i[2]*0.08),int(i[1]-i[3]*0.08),int(i[0]+i[2]*1.1),int(i[1]+i[3]*1.1)) for i in Rect]\n",
    "    return RectP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./fapiao/IMG_20190312_102653.jpg\")\n",
    "crop_img = crop_img_price(img)\n",
    "rect = text_detect(crop_img)\n",
    "for i in rect:\n",
    "    cv2.rectangle(crop_img,i[:2],i[2:],(0,0,255))\n",
    "cv2.imshow(\"img\", crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrib_text_detection(img):\n",
    "    vis      = img.copy()\n",
    "\n",
    "    pathname = \"./openCV_Cpp_samples\"\n",
    "    # Extract channels to be processed individually\n",
    "    channels = cv2.text.computeNMChannels(img)\n",
    "    # Append negative channels to detect ER- (bright regions over dark background)\n",
    "    cn = len(channels)-1\n",
    "    for c in range(0,cn):\n",
    "          channels.append((255-channels[c]))\n",
    "\n",
    "    # Apply the default cascade classifier to each independent channel (could be done in parallel)\n",
    "    print(\"Extracting Class Specific Extremal Regions from \"+str(len(channels))+\" channels ...\")\n",
    "    print(\"    (...) this may take a while (...)\")\n",
    "    for channel in channels:\n",
    "        erc1 = cv2.text.loadClassifierNM1(pathname+'/trained_classifierNM1.xml')\n",
    "        er1 = cv2.text.createERFilterNM1(erc1,16,0.00015,0.13,0.2,True,0.1)\n",
    "\n",
    "        erc2 = cv2.text.loadClassifierNM2(pathname+'/trained_classifierNM2.xml')\n",
    "        er2 = cv2.text.createERFilterNM2(erc2,0.5)\n",
    "\n",
    "        regions = cv2.text.detectRegions(channel,er1,er2)\n",
    "\n",
    "        rects = cv2.text.erGrouping(img,channel,[r.tolist() for r in regions])\n",
    "        #rects = cv2.text.erGrouping(img,channel,[x.tolist() for x in regions], cv2.text.ERGROUPING_ORIENTATION_ANY,'../../GSoC2014/opencv_contrib/modules/text/samples/trained_classifier_erGrouping.xml',0.5)\n",
    "\n",
    "        #Visualization\n",
    "        for r in range(0,np.shape(rects)[0]):\n",
    "            rect = rects[r]\n",
    "            cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "            cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "    #Visualization\n",
    "    cv2.imshow(\"Text detection result\", vis)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./fapiao/IMG_20190312_102653.jpg\")\n",
    "crop_img = crop_img_id(img)\n",
    "contrib_text_detection(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
